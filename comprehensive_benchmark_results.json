{
  "metadata": {
    "date": "2025-11-15T20:01:09.451869",
    "platform": "Mac (Intel)",
    "model": "gpt2",
    "num_texts": 100,
    "patch_tokenizer_path": null,
    "larosa_sparsity": 0.4
  },
  "normal_llm": {
    "system": "normal_llm",
    "model_name": "gpt2",
    "num_texts": 100,
    "tokenization": {
      "vocab_size": 50257,
      "total_tokens": 2160,
      "avg_tokens_per_text": 21.6,
      "tokens_per_text": [
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19
      ],
      "tokenization_time": 0.01875925064086914,
      "throughput_texts_per_sec": 5330.703337485066
    },
    "kv_cache": {
      "estimated_per_token_bytes": 36864,
      "estimated_total_bytes": 79626240,
      "estimated_total_mb": 75.9375,
      "estimated_per_text_mb": 0.759375,
      "note": "Theoretical estimation - actual depends on model architecture"
    },
    "performance": {
      "total_time_seconds": 0.01875925064086914,
      "tokens_per_second": 115143.19208967744,
      "texts_per_second": 5330.703337485066,
      "avg_time_per_text_ms": 0.1875925064086914
    }
  },
  "larosa_llm": {
    "system": "larosa_llm",
    "model_name": "gpt2",
    "num_texts": 100,
    "sparsity": 0.4,
    "tokenization": {
      "vocab_size": 50257,
      "total_tokens": 19,
      "avg_tokens_per_text": 19.0,
      "tokens_per_text": [
        19
      ],
      "tokenization_time": 0.0003991127014160156,
      "throughput_texts_per_sec": 2505.557945041816
    },
    "kv_cache": {
      "estimated_per_token_bytes": 36864,
      "estimated_total_bytes": 700416,
      "estimated_total_mb": 0.66796875,
      "estimated_per_text_mb": 0.66796875,
      "note": "Theoretical estimation - actual depends on model architecture"
    },
    "performance": {
      "total_time_seconds": 0.0003991127014160156,
      "tokens_per_second": 47605.60095579451,
      "texts_per_second": 250555.7945041816,
      "texts_per_second_with_larosa": 325722.5328554361,
      "speedup_factor": 1.3,
      "avg_time_per_text_ms": 0.003991127014160156
    },
    "activation_sparsity": {
      "target_sparsity": 0.4,
      "estimated_speedup": 1.3,
      "activation_reduction_percent": 40.0,
      "note": "Theoretical estimation - LaRoSA requires GPU for real measurement",
      "larosa_enabled": false
    }
  },
  "fused_llm": {
    "system": "fused_llm",
    "model_name": "gpt2",
    "num_texts": 100,
    "tokenization": {
      "vocab_size": 50257,
      "total_tokens": 2160,
      "avg_tokens_per_text": 21.6,
      "tokens_per_text": [
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19
      ],
      "tokenization_time": 0.01605391502380371,
      "throughput_texts_per_sec": 6229.010173015519,
      "adaptivocab_enabled": false
    },
    "kv_cache": {
      "estimated_per_token_bytes": 36864,
      "estimated_total_bytes": 67682304.0,
      "estimated_total_mb": 64.546875,
      "estimated_per_text_mb": 0.64546875,
      "vattention_efficiency_factor": 0.85,
      "vattention_savings_percent": 15.000000000000002,
      "note": "Theoretical estimation with vAttention optimization",
      "vattention_enabled": false
    },
    "performance": {
      "total_time_seconds": 0.01605391502380371,
      "tokens_per_second": 134546.61973713522,
      "texts_per_second": 6229.010173015519,
      "avg_time_per_text_ms": 0.1605391502380371
    },
    "optimizations": {
      "adaptivocab_enabled": false,
      "vattention_enabled": false
    }
  },
  "improvements": {
    "normal_vs_fused": {
      "token_reduction_percent": 0.0,
      "tokens_saved": 0,
      "kv_cache_reduction_percent": 15.0,
      "kv_cache_saved_mb": 11.390625,
      "speed_improvement_percent": 16.851563080121785
    },
    "normal_vs_larosa": {
      "activation_sparsity_percent": 40.0,
      "estimated_speedup": 1.3
    }
  }
}