{
  "metadata": {
    "date": "2025-11-15T19:19:29.639783",
    "platform": "Mac (Intel)",
    "model": "gpt2",
    "num_texts": 100,
    "patch_tokenizer_path": null
  },
  "normal_llm": {
    "system": "normal_llm",
    "model_name": "gpt2",
    "num_texts": 100,
    "tokenization": {
      "vocab_size": 50257,
      "total_tokens": 2160,
      "avg_tokens_per_text": 21.6,
      "tokens_per_text": [
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19
      ],
      "tokenization_time": 0.11725616455078125,
      "throughput_texts_per_sec": 852.8336261305225
    },
    "kv_cache": {
      "estimated_per_token_bytes": 36864,
      "estimated_total_bytes": 79626240,
      "estimated_total_mb": 75.9375,
      "estimated_per_text_mb": 0.759375,
      "note": "Theoretical estimation - actual depends on model architecture"
    },
    "performance": {
      "total_time_seconds": 0.11725616455078125,
      "tokens_per_second": 18421.206324419287,
      "texts_per_second": 852.8336261305225,
      "avg_time_per_text_ms": 1.1725616455078125
    }
  },
  "fused_llm": {
    "system": "fused_llm",
    "model_name": "gpt2",
    "num_texts": 100,
    "tokenization": {
      "vocab_size": 50257,
      "total_tokens": 2160,
      "avg_tokens_per_text": 21.6,
      "tokens_per_text": [
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19,
        19,
        22,
        23,
        25,
        23,
        24,
        21,
        20,
        20,
        19
      ],
      "tokenization_time": 0.11792111396789551,
      "throughput_texts_per_sec": 848.0245533232106,
      "adaptivocab_enabled": false
    },
    "kv_cache": {
      "estimated_per_token_bytes": 36864,
      "estimated_total_bytes": 71663616.0,
      "estimated_total_mb": 68.34375,
      "estimated_per_text_mb": 0.6834375,
      "memory_efficiency_factor": 0.9,
      "memory_savings_percent": 9.999999999999998,
      "memory_backend": "PagedAttention",
      "note": "Theoretical estimation with PagedAttention optimization",
      "vattention_enabled": false,
      "pagedattention_enabled": true
    },
    "performance": {
      "total_time_seconds": 0.11792111396789551,
      "tokens_per_second": 18317.33035178135,
      "texts_per_second": 848.0245533232106,
      "avg_time_per_text_ms": 1.179211139678955
    },
    "optimizations": {
      "adaptivocab_enabled": false,
      "memory_backend": "pagedattention",
      "vattention_enabled": false,
      "pagedattention_enabled": true
    }
  },
  "improvements": {
    "token_reduction_percent": 0.0,
    "tokens_saved": 0,
    "kv_cache_reduction_percent": 10.0,
    "kv_cache_saved_mb": 7.59375,
    "speed_improvement_percent": -0.5638934324308458
  }
}